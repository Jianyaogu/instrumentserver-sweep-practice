{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27496f9-7bab-4734-8ad2-b6f782475068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Optional, Callable, Sequence, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from labcore.data.datadict import DataDict\n",
    "from labcore.data.datadict_storage import datadict_from_hdf5\n",
    "from labcore.measurement.storage import run_and_save_sweep\n",
    "\n",
    "from qcui_measurement.protocols.base import ProtocolOperation\n",
    "from qcui_measurement.protocols.parameters import (\n",
    "    Repetition, Steps,\n",
    "    StartReadoutFrequency, EndReadoutFrequency,\n",
    "    ReadoutGain, ReadoutLength, Delay,\n",
    ")\n",
    "from qcui_measurement.protocols.operations.res_spec import ResonatorSpectroscopy\n",
    "from qcui_measurement.qick.single_transmon_v2 import FreqSweepProgram\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# --------------------------- helpers & containers -----------------------------\n",
    "# This part defines some functions that unwrap the signal and fit for a mixture of two hangers instead of the single standard complex hanger (notch) model\n",
    "@dataclass\n",
    "class FluxList:\n",
    "    name: str\n",
    "    value: Iterable[float]\n",
    "\n",
    "def _unwrap_and_remove_linear_phase(freq: np.ndarray, sig: np.ndarray) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"Unwrap phase and remove best-fit linear slope (cable delay).\"\"\"\n",
    "    # unwrap and linear fit: angle ≈ φ0 + 2π τ f, so it becomes continuous\n",
    "    ph = np.unwrap(np.angle(sig))\n",
    "    slope = np.polyfit(freq, ph, 1)[0]\n",
    "    sig_unw = sig * np.exp(-1j * slope * freq)\n",
    "    return sig_unw, slope/(2*np.pi)  # return τ estimate in seconds if freq in Hz\n",
    "\n",
    "def _hanger_single(f: np.ndarray, f0, Ql, Qc, theta, a, phi0, tau) -> np.ndarray:\n",
    "    x = (f - f0) / f0\n",
    "    notch = 1.0 - (Ql/Qc) * np.exp(1j*theta) / (1.0 + 2j*Ql*x)\n",
    "    return a * np.exp(1j*(phi0 + 2*np.pi*f*tau)) * notch\n",
    "\n",
    "def _hanger_double_mix(f: np.ndarray, params: Dict[str, float]) -> np.ndarray:\n",
    "    \"\"\"Mixture of two nearby resonances with shared line params, weighted by p_g.\"\"\"\n",
    "    f0g, f0e = params[\"f0g\"], params[\"f0e\"]\n",
    "    Ql, Qc   = params[\"Ql\"],  params[\"Qc\"]\n",
    "    theta    = params[\"theta\"]\n",
    "    a        = params[\"a\"]\n",
    "    phi0     = params[\"phi0\"]\n",
    "    tau      = params[\"tau\"]\n",
    "    pg       = params[\"pg\"]  # in [0,1]\n",
    "    s_g = _hanger_single(f, f0g, Ql, Qc, theta, a, phi0, tau)\n",
    "    s_e = _hanger_single(f, f0e, Ql, Qc, theta, a, phi0, tau)\n",
    "    return pg*s_g + (1.0 - pg)*s_e\n",
    "\n",
    "def _fit_double_hanger(freq: np.ndarray, sig_cplx: np.ndarray):\n",
    "    f = np.asarray(freq, float)\n",
    "    yC = np.asarray(sig_cplx, complex)\n",
    "\n",
    "    # -------- de-embed linear phase (done in your pipeline, but safe here) --------\n",
    "    ph = np.unwrap(np.angle(yC))\n",
    "    b1, b0 = np.polyfit(f, ph, 1)         # ph ≈ b0 + b1 f\n",
    "    y = yC * np.exp(-1j * (b0 + b1*f))    # unwrapped/de-sloped\n",
    "    # NOTE: we fit in this frame; we won't refit tau here.\n",
    "\n",
    "    # -------- initial guesses via local minima on smoothed |S| --------\n",
    "    mag = np.abs(y)\n",
    "    win = max(5, len(f)//80)\n",
    "    mag_s = np.convolve(mag, np.ones(win)/win, mode=\"same\")\n",
    "\n",
    "    # local minima: indices i with mag_s[i] < neighbors\n",
    "    locmins = np.where((mag_s[1:-1] < mag_s[:-2]) & (mag_s[1:-1] < mag_s[2:]))[0] + 1\n",
    "    if len(locmins) == 0:\n",
    "        locmins = np.array([int(np.argmin(mag_s))])\n",
    "    # sort by depth\n",
    "    locmins = locmins[np.argsort(mag_s[locmins])]\n",
    "\n",
    "    # pick the deepest as ground; the closest *distinct* other min as excited\n",
    "    i0 = locmins[0]\n",
    "    # distinct = at least a few bins away\n",
    "    min_sep_bins = max(5, len(f)//200)\n",
    "    candidates = [j for j in locmins[1:] if abs(j - i0) >= min_sep_bins]\n",
    "    j0 = candidates[0] if candidates else (i0 + min_sep_bins if i0 + min_sep_bins < len(f) else i0 - min_sep_bins)\n",
    "\n",
    "    f0g0, f0e0 = np.sort([f[i0], f[j0]])\n",
    "\n",
    "    # -------- line-term seeds (gentle) --------\n",
    "    a0 = float(np.median(mag))\n",
    "    theta0 = 0.0\n",
    "    phi00 = 0.0\n",
    "    tau0 = 0.0\n",
    "    Ql0, Qc0 = 1.5e4, 3.0e4\n",
    "    pg0 = 0.7\n",
    "\n",
    "    # -------- bounds with a narrow f0e window around its seed --------\n",
    "    # estimate natural linewidth ~ f0 / Ql0; allow a wide multiple\n",
    "    linewidth = f0g0 / Ql0\n",
    "    df_win = max(10.0*linewidth, 1.5e6)   # e.g. +/- 1.5 MHz minimum window\n",
    "    lb = dict(f0g=f.min(),  f0e=f0e0 - 4*df_win, Ql=500,  Qc=500,\n",
    "              theta=-np.pi, a=0.0, phi0=-np.pi, tau=-1e-6, pg=0.0)\n",
    "    ub = dict(f0g=f.max(),  f0e=f0e0 + 4*df_win, Ql=5e5, Qc=5e6,\n",
    "              theta= np.pi, a=10*np.max(mag), phi0= np.pi, tau= 1e-6, pg=1.0)\n",
    "\n",
    "    params0 = dict(f0g=f0g0, f0e=f0e0, Ql=Ql0, Qc=Qc0, theta=theta0, a=a0, phi0=phi00, tau=tau0, pg=pg0)\n",
    "\n",
    "    # -------- model & packing --------\n",
    "    def _hanger_single(ff, f0, Ql, Qc, theta, a, phi0, tau):\n",
    "        x = (ff - f0)/f0\n",
    "        notch = 1.0 - (Ql/Qc)*np.exp(1j*theta)/(1.0 + 2j*Ql*x)\n",
    "        return a*np.exp(1j*(phi0 + 2*np.pi*ff*tau))*notch\n",
    "\n",
    "    def _hanger_double_mix(ff, p):\n",
    "        sg = _hanger_single(ff, p[\"f0g\"], p[\"Ql\"], p[\"Qc\"], p[\"theta\"], p[\"a\"], p[\"phi0\"], p[\"tau\"])\n",
    "        se = _hanger_single(ff, p[\"f0e\"], p[\"Ql\"], p[\"Qc\"], p[\"theta\"], p[\"a\"], p[\"phi0\"], p[\"tau\"])\n",
    "        return p[\"pg\"]*sg + (1.0 - p[\"pg\"])*se\n",
    "\n",
    "    keys = [\"f0g\",\"f0e\",\"Ql\",\"Qc\",\"theta\",\"a\",\"phi0\",\"tau\",\"pg\"]\n",
    "    def pack(p):   return np.array([p[k] for k in keys], float)\n",
    "    def unpack(v): return {k: float(x) for k,x in zip(keys, v)}\n",
    "\n",
    "    v0  = pack(params0)\n",
    "    vlb = pack(lb)\n",
    "    vub = pack(ub)\n",
    "\n",
    "    # -------- residual with weights (emphasize dips) --------\n",
    "    # weight ~ 1/(mag_s^2) but bounded to avoid extremes\n",
    "    w = 1.0/np.maximum(mag_s**2, 1e-4)\n",
    "    w = w/np.max(w)\n",
    "    def resid(v):\n",
    "        p = unpack(v)\n",
    "        s = _hanger_double_mix(f, p)\n",
    "        r = np.stack([np.real(s) - np.real(y), np.imag(s) - np.imag(y)], axis=1)\n",
    "        r = (r.T * w).T     # apply weights pointwise to both Re/Im\n",
    "        return r.ravel()\n",
    "\n",
    "    # -------- optimize (SciPy if present, else projected gradient) --------\n",
    "    try:\n",
    "        from scipy.optimize import least_squares\n",
    "        res = least_squares(resid, v0, bounds=(vlb, vub), xtol=1e-12, ftol=1e-12, gtol=1e-12, max_nfev=4000)\n",
    "        vf = res.x\n",
    "    except Exception:\n",
    "        vf = v0.copy()\n",
    "        lr = 2e-6\n",
    "        eps = np.array([5e3, 5e3, 50.0, 50.0, 1e-3, 1e-3, 1e-3, 1e-9, 1e-2])\n",
    "        for _ in range(800):\n",
    "            r0 = resid(vf); base = np.dot(r0, r0)\n",
    "            g = np.zeros_like(vf)\n",
    "            for k in range(len(vf)):\n",
    "                vtmp = vf.copy(); vtmp[k] = np.clip(vtmp[k] + eps[k], vlb[k], vub[k])\n",
    "                r2 = resid(vtmp); g[k] = (np.dot(r2,r2) - base)/eps[k]\n",
    "            vf -= lr*g\n",
    "            vf = np.minimum(np.maximum(vf, vlb), vub)\n",
    "\n",
    "    p_fit = unpack(vf)\n",
    "    # enforce ordering convention\n",
    "    if p_fit[\"f0g\"] > p_fit[\"f0e\"]:\n",
    "        p_fit[\"f0g\"], p_fit[\"f0e\"] = p_fit[\"f0e\"], p_fit[\"f0g\"]\n",
    "        p_fit[\"pg\"] = 1.0 - p_fit[\"pg\"]\n",
    "\n",
    "    # derived Qi and a simple SNR proxy\n",
    "    Qi = (p_fit[\"Ql\"]*p_fit[\"Qc\"])/max(p_fit[\"Qc\"] - p_fit[\"Ql\"], 1e-6)\n",
    "    rr = resid(vf).reshape(-1,2)\n",
    "    noise = np.std(np.hypot(rr[:,0], rr[:,1]))\n",
    "    amp = np.max(mag) - np.min(mag)\n",
    "    snr = float(abs(amp)/(4*max(noise, 1e-12)))\n",
    "    return p_fit, {\"Qi\": Qi}, snr\n",
    "\n",
    "from scipy.signal import find_peaks  # at top once\n",
    "\n",
    "# Fast magnitude-only dip counter (no fitting)\n",
    "def _count_dips_fast(freq_Hz: np.ndarray, sig_row: np.ndarray) -> int:\n",
    "    sig_unw, _ = _unwrap_and_remove_linear_phase(freq_Hz, sig_row)\n",
    "    mag = np.abs(sig_unw)\n",
    "    win = max(5, len(mag)//200);  win += (win % 2 == 0)\n",
    "    mag_s = np.convolve(mag, np.ones(win)/win, mode=\"same\")\n",
    "    peaks, _ = find_peaks(-mag_s,\n",
    "                          prominence=0.15*np.ptp(mag_s),\n",
    "                          distance=max(5, len(mag)//150))\n",
    "    return int(len(peaks))\n",
    "\n",
    "# Decide once whether to use single or double for the whole dataset\n",
    "def _decide_model(f_Hz: np.ndarray, sig2d: np.ndarray,\n",
    "                  sample_every: int = 10,\n",
    "                  frac_single_threshold: float = 0.75) -> str:\n",
    "    idx = np.arange(0, len(sig2d), sample_every)\n",
    "    counts = np.array([_count_dips_fast(f_Hz, sig2d[i]) for i in idx])\n",
    "    return \"single\" if np.mean(counts <= 1) >= frac_single_threshold else \"double\"\n",
    "\n",
    "# Find linear slope. Fit y ≈ a*(x-x0) + b on [x0-halfwidth, x0+halfwidth]; return slope a\n",
    "def _local_linear_slope(x, y, x0, halfwidth):\n",
    "    lo, hi = x0 - halfwidth, x0 + halfwidth\n",
    "    mask = (x >= lo) & (x <= hi)\n",
    "    xx, yy = x[mask], y[mask]\n",
    "    if len(xx) < 3:\n",
    "        return np.nan\n",
    "    u = xx - x0\n",
    "    a, b = np.polyfit(u, yy, 1)   # slope, intercept\n",
    "    return float(a)\n",
    "\n",
    "# Symmetry score at center c: score = RMS_{j} [ y(c+Δ_j) - y(c-Δ_j) ] / scale\n",
    "# where Δ_j are n_pairs offsets in (0, halfwidth], and y is linearly interpolated\n",
    "def _symmetry_score(x, y, c, halfwidth, n_pairs, eps=1e-12):\n",
    "    # build offsets that are available on both sides within data range\n",
    "    Δmax = min(c - x[0], x[-1] - c, halfwidth)\n",
    "    if Δmax <= 0:\n",
    "        return np.inf\n",
    "    Δ = np.linspace(Δmax/n_pairs, Δmax, n_pairs)\n",
    "\n",
    "    yp = np.interp(c + Δ, x, y)\n",
    "    ym = np.interp(c - Δ, x, y)\n",
    "\n",
    "    r = yp - ym\n",
    "    rms = np.sqrt(np.mean(r*r))\n",
    "\n",
    "    # robust scale for normalization (MAD over data)\n",
    "    med = np.median(y)\n",
    "    mad = np.median(np.abs(y - med)) + eps\n",
    "    return float(rms / mad)\n",
    "\n",
    "\n",
    "# ------------------------------ main protocol --------------------------------\n",
    "\n",
    "class ResonatorSpectroscopyVsFlux(ProtocolOperation):\n",
    "    \"\"\"\n",
    "    Resonator spectroscopy vs flux with two-branch (g/e) hanger fitting.\n",
    "\n",
    "    Supports either:\n",
    "      - global start/end readout frequency (params), or\n",
    "      - per-flux start/end lists via `start_freq_list`, `end_freq_list`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        params,\n",
    "        *,\n",
    "        flux_list: FluxList,\n",
    "        repetitions: Optional[Repetition] = None,\n",
    "        steps: Steps,\n",
    "        start_freq: StartReadoutFrequency,\n",
    "        end_freq: EndReadoutFrequency,\n",
    "        readout_gain: ReadoutGain,\n",
    "        length: ReadoutLength,\n",
    "        delay: Delay,\n",
    "        set_flux: Optional[Callable[[float], None]] = None,\n",
    "        # optional per-flux frequency windows (MHz). If provided, must match flux_list length.\n",
    "        start_freq_list: Optional[Sequence[float]] = None,\n",
    "        end_freq_list:   Optional[Sequence[float]] = None,\n",
    "        name: Optional[str] = None,\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        # I/O (aligned with other ops)\n",
    "        self._register_inputs(\n",
    "            repetitions or Repetition(params),\n",
    "            steps,\n",
    "            start_freq, end_freq,\n",
    "            readout_gain, length, delay,\n",
    "        )\n",
    "        self._register_outputs(readout_if=StartReadoutFrequency(params))\n",
    "\n",
    "        # controls\n",
    "        self.flux_values = np.asarray(list(flux_list.value), float)\n",
    "        self.set_flux = set_flux\n",
    "        self.start_freq_list = np.asarray(start_freq_list, float) if start_freq_list is not None else None\n",
    "        self.end_freq_list   = np.asarray(end_freq_list,   float) if end_freq_list   is not None else None\n",
    "\n",
    "        # data cache\n",
    "        self.model_choice: Optional[str] = None\n",
    "        self.independents = {\"flux\": [], \"frequencies\": []}\n",
    "        self.dependents = {\"signal\": []}  # shape (Nphi, Nf) complex\n",
    "        self.data_loc: Optional[Path] = None\n",
    "\n",
    "        # fit results\n",
    "        self.fr_g:  list[float] = []\n",
    "        self.fr_e:  list[float] = []\n",
    "        self.Ql:    list[float] = []\n",
    "        self.Qc:    list[float] = []\n",
    "        self.Qi:    list[float] = []\n",
    "        self.pg:    list[float] = []\n",
    "        self.snr:   list[float] = []\n",
    "\n",
    "        self.figure_paths: list[Path] = []\n",
    "        self.condition = \"Success if dataset collected and fits converge.\"\n",
    "\n",
    "    # ------------------------------- measure ---------------------------------\n",
    "\n",
    "    def _measure_quick(self) -> Path:\n",
    "        logger.info(\"Starting resonator spectroscopy vs flux measurement\")\n",
    "\n",
    "        rows = []\n",
    "        last_loc: Optional[Path] = None\n",
    "\n",
    "        for i, phi in enumerate(self.flux_values):\n",
    "            logger.debug(f\"[{i+1}/{len(self.flux_values)}] Set flux → {phi}\")\n",
    "            if self.set_flux is not None:\n",
    "                self.set_flux(phi)\n",
    "\n",
    "            sweep = FreqSweepProgram()\n",
    "\n",
    "            # (Optional) configure program’s sweep window here if your driver exposes it.\n",
    "            # If your FreqSweepProgram reads parameters from Start/EndReadoutFrequency only,\n",
    "            # you can instead run multiple small sweeps by setting params before calling.\n",
    "\n",
    "            file_label = f\"{self.name or 'res_spec_vs_flux'}_phi={phi:.6f}\"\n",
    "            loc, _ = run_and_save_sweep(sweep, \"data\", file_label)\n",
    "            last_loc = Path(loc)\n",
    "\n",
    "            dd = datadict_from_hdf5(last_loc / \"data.ddh5\")\n",
    "            freqs = np.asarray(dd[\"freq\"][\"values\"])    # MHz\n",
    "            sig   = np.asarray(dd[\"signal\"][\"values\"])  # complex, shape (Nf,)\n",
    "            rows.append((phi, freqs, sig))\n",
    "\n",
    "        if not rows:\n",
    "            raise RuntimeError(\"No data collected.\")\n",
    "\n",
    "        # pack into a single DataDict on a common frequency grid (assume same config)\n",
    "        flux_vals = np.array([r[0] for r in rows])\n",
    "        freqs_ref = rows[0][1]\n",
    "        sig_matrix = np.vstack([r[2] for r in rows])  # (Nphi, Nf)\n",
    "\n",
    "        out = DataDict(\n",
    "            freq  = dict(values=freqs_ref),\n",
    "            flux  = dict(values=flux_vals),\n",
    "            signal= dict(values=sig_matrix, axes=[\"flux\", \"freq\"]),\n",
    "        )\n",
    "\n",
    "        final_dir = (last_loc.parent if last_loc else Path(\".\")).resolve()\n",
    "        final_path = final_dir / \"data.ddh5\"\n",
    "        out.save(final_path)\n",
    "        logger.info(f\"Saved 2D dataset → {final_path}\")\n",
    "\n",
    "        # cache\n",
    "        self.independents[\"frequencies\"] = freqs_ref\n",
    "        self.independents[\"flux\"]        = flux_vals\n",
    "        self.dependents[\"signal\"]        = sig_matrix\n",
    "        self.data_loc = final_dir\n",
    "        return final_dir\n",
    "\n",
    "    def _load_data_quick(self):\n",
    "        path = Path(self.data_loc) / \"data.ddh5\"\n",
    "        dd = datadict_from_hdf5(path)\n",
    "        self.independents[\"frequencies\"] = np.asarray(dd[\"freq\"][\"values\"])\n",
    "        self.independents[\"flux\"]        = np.asarray(dd[\"flux\"][\"values\"])\n",
    "        self.dependents[\"signal\"]        = np.asarray(dd[\"signal\"][\"values\"])\n",
    "\n",
    "    # -------------------------------- analyze --------------------------------\n",
    "\n",
    "    def analyze(self):\n",
    "        \"\"\"Fit the spectroscopy map and produce fr_g / fr_e (fr_e=nan for single).\"\"\"\n",
    "        if self.data_loc is None or not self.independents.get(\"frequencies\", []):\n",
    "            self._load_data_quick()\n",
    "\n",
    "        freqs_MHz: np.ndarray = np.asarray(self.independents[\"frequencies\"])  # MHz\n",
    "        flux_vals: np.ndarray = np.asarray(self.independents[\"flux\"])\n",
    "        sig2d: np.ndarray     = np.asarray(self.dependents[\"signal\"])         # (Nphi, Nf)\n",
    "\n",
    "        f_Hz = freqs_MHz * 1e6\n",
    "\n",
    "        # Decide model once for the whole dataset\n",
    "        self.model_choice = _decide_model(f_Hz, sig2d)\n",
    "        logger.info(f\"[res_spec_vs_flux] model_choice = {self.model_choice}\")\n",
    "\n",
    "        # reset outputs\n",
    "        self.fr_g.clear(); self.fr_e.clear()\n",
    "        self.Qc.clear();   self.Ql.clear(); self.Qi.clear()\n",
    "        self.pg.clear();   self.snr.clear()\n",
    "\n",
    "        if self.model_choice == \"single\":\n",
    "            # single-notch per row → keep API stable by writing fr_e = nan\n",
    "            for phi, sig_row in zip(flux_vals, sig2d):\n",
    "                # Same as res_spec vs gain\n",
    "                ret = ResonatorSpectroscopy.add_mag_and_unwind_and_fit(\n",
    "                    freqs_MHz, sig_row, label=f\"Φ={phi:.6g}\"\n",
    "                )\n",
    "        \n",
    "                params = ret.fit_result.params  # lmfit.Parameters object\n",
    "        \n",
    "                # Extract results (use .value safely)\n",
    "                f0 = params[\"f_0\"].value if \"f_0\" in params else np.nan\n",
    "                Ql = params[\"Q_l\"].value if \"Q_l\" in params else np.nan\n",
    "                Qc = params[\"Q_c\"].value if \"Q_c\" in params else np.nan\n",
    "                Qi = params[\"Q_i\"].value if \"Q_i\" in params else (\n",
    "                    (Ql * Qc) / (Qc - Ql) if (Qc > Ql) else np.nan\n",
    "                )\n",
    "        \n",
    "                # Append results (keep structure same as double fit)\n",
    "                self.fr_g.append(f0)         # in MHz\n",
    "                self.fr_e.append(np.nan)     # single-notch: no excited branch\n",
    "                self.Ql.append(Ql)\n",
    "                self.Qc.append(Qc)\n",
    "                self.Qi.append(Qi)\n",
    "                self.pg.append(np.nan)\n",
    "                self.snr.append(float(ret.snr))\n",
    "        else:\n",
    "            # double-hanger for every row (your current path)\n",
    "            for phi, sig_row in zip(flux_vals, sig2d):\n",
    "                sig_unw, _ = _unwrap_and_remove_linear_phase(f_Hz, sig_row)\n",
    "                p_fit, derived, snr = _fit_double_hanger(f_Hz, sig_unw)\n",
    "\n",
    "                self.fr_g.append(p_fit[\"f0g\"]/ 1e6)  # change to MHz\n",
    "                self.fr_e.append(p_fit[\"f0e\"]/ 1e6)  # change to MHz\n",
    "                self.Ql.append(p_fit[\"Ql\"])\n",
    "                self.Qc.append(p_fit[\"Qc\"])\n",
    "                self.Qi.append(derived[\"Qi\"])\n",
    "                self.pg.append(p_fit[\"pg\"])\n",
    "                self.snr.append(snr)\n",
    "\n",
    "    # -------------------------------- evaluate -------------------------------\n",
    "\n",
    "    def evaluate(self) -> bool:\n",
    "        \"\"\"Simple pass/fail placeholder: all SNRs above a minimal threshold.\"\"\"\n",
    "        if not self.snr:\n",
    "            self.report_output = [\"No fits yet. Did you call analyze()?\"]\n",
    "            return False\n",
    "        snr_thr = 2.0\n",
    "        ok = bool(np.all(np.asarray(self.snr) >= snr_thr))\n",
    "        msg = (\n",
    "            f\"## Resonator Spectroscopy vs Flux\\n\"\n",
    "            f\"Flux points: {len(self.snr)}\\n\"\n",
    "            f\"SNR min/median/max: {np.min(self.snr):.2f} / {np.median(self.snr):.2f} / {np.max(self.snr):.2f}\\n\"\n",
    "            f\"Pass threshold: {snr_thr}\\n\"\n",
    "        )\n",
    "        self.report_output = [msg]\n",
    "        return ok\n",
    "\n",
    "\n",
    "    def find_zero_flux_point(\n",
    "        self,\n",
    "        halfwidth_sym: float | None = None,  # window half-width around candidate (same units as flux)\n",
    "        n_pairs: int = 25,                    # mirrored pairs for symmetry score\n",
    "        halfwidth_slope: float | None = None, # window half-width for local slope fit\n",
    "        slope_tol: float | None = None,       # flatness threshold on |slope|\n",
    "        score_rel_drop: float = 0.25,         # how deep a local min must be vs neighbors\n",
    "        max_candidates: int = 8\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Find centers where the curve (f0 in single or f_r,g in double) is most even and locally flat.\n",
    "        Uses self.fr_g only (fr_g == f0 in single model).\n",
    "        Returns dict with: picked (list of {center, score, slope}), candidates, status, notes.\n",
    "        \"\"\"\n",
    "        # x: flux/current; y: frequency track to use\n",
    "        x = np.asarray(self.independents[\"flux\"], float)\n",
    "        y = np.asarray(self.fr_g, float)   # <-- single: f0; double: f_r,g\n",
    "    \n",
    "        # keep finite points\n",
    "        m = np.isfinite(x) & np.isfinite(y)\n",
    "        x, y = x[m], y[m]\n",
    "        N = len(x)\n",
    "        if N < 7:\n",
    "            return dict(picked=[], candidates=[], status=\"bad_input\", notes=[\"too few finite points\"])\n",
    "    \n",
    "        # defaults for windows\n",
    "        span = x[-1] - x[0]\n",
    "        if halfwidth_sym   is None: halfwidth_sym   = 0.10 * span\n",
    "        if halfwidth_slope is None: halfwidth_slope = 0.05 * span\n",
    "    \n",
    "        # data-driven slope tolerance if not provided\n",
    "        dy = np.gradient(y, x)\n",
    "        med_abs_slope = np.nanmedian(np.abs(dy))\n",
    "        if slope_tol is None:\n",
    "            slope_tol = 0.25 * (med_abs_slope if np.isfinite(med_abs_slope) else 1.0)\n",
    "    \n",
    "        # symmetry score at each x[k]\n",
    "        scores = np.empty(N, float)\n",
    "        for k in range(N):\n",
    "            scores[k] = _symmetry_score(x, y, x[k], halfwidth_sym, n_pairs)\n",
    "    \n",
    "        # pick local minima of the score (5-point neighborhood)\n",
    "        winsize = 5; halfw = winsize // 2\n",
    "        candidates = []\n",
    "        for k in range(halfw, N - halfw):\n",
    "            local_avg = float(np.mean(scores[k - halfw:k + halfw + 1]))\n",
    "            if scores[k] <= (1.0 - score_rel_drop) * local_avg:\n",
    "                c = float(x[k])\n",
    "                slope = _local_linear_slope(x, y, c, halfwidth_slope)\n",
    "                candidates.append(dict(center=c, score=float(scores[k]), slope=float(slope)))\n",
    "    \n",
    "        # keep best few by score, then enforce flatness\n",
    "        candidates = sorted(candidates, key=lambda d: d[\"score\"])[:max_candidates]\n",
    "        picked = [c for c in candidates if np.isfinite(c[\"slope\"]) and abs(c[\"slope\"]) <= slope_tol]\n",
    "    \n",
    "        notes = [\n",
    "            f\"model={self.model_choice or 'unknown'} (using fr_g: f0 in single, f_r,g in double)\",\n",
    "            f\"halfwidth_sym={halfwidth_sym:.3g}\",\n",
    "            f\"halfwidth_slope={halfwidth_slope:.3g}\",\n",
    "            f\"slope_tol={slope_tol:.3g}\",\n",
    "            f\"score_rel_drop={score_rel_drop}\",\n",
    "            f\"n_pairs={n_pairs}\",\n",
    "            f\"span={span:.3g}, N={N}\",\n",
    "        ]\n",
    "        status = \"ok\" if picked else \"no_flat_even_center_found\"\n",
    "        return dict(picked=picked, candidates=candidates, status=status, notes=notes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3567ecc-0a8e-4a2b-b7f0-2aacc006b6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b51d4-b2b6-443a-aee7-80edf163c2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65267cb1-a774-40a2-9ce3-0928795c0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell for the protocol above\n",
    "params = ...  # given by initial guess modules and should contain steps, delay, gain\n",
    "fluxes = FluxList(name=\"PhiPhi0\", value=np.linspace(0, 2*np.pi, 101))\n",
    "\n",
    "def set_flux(phi):\n",
    "    # send phi to your DAC/flux-bias line\n",
    "    ...\n",
    "\n",
    "op = ResonatorSpectroscopyVsFlux(\n",
    "    params,\n",
    "    flux_list=fluxes,\n",
    "    repetitions=Repetition(params),\n",
    "    steps=Steps(params),\n",
    "    start_freq=StartReadoutFrequency(params),\n",
    "    end_freq=EndReadoutFrequency(params),\n",
    "    readout_gain=ReadoutGain(params),\n",
    "    length=ReadoutLength(params),\n",
    "    delay=Delay(params),\n",
    "    set_flux=set_flux,\n",
    "    # optional tighter per-flux scan windows:\n",
    "    # start_freq_list=[...], end_freq_list=[...],\n",
    "    name=\"res_spec_vs_flux\"\n",
    ")\n",
    "\n",
    "data_dir = op._measure_quick()                # collect sweeps → data.ddh5 (2D)\n",
    "op.analyze()                                  # fit double hanger per flux row\n",
    "ok = op.evaluate()                            # QA gate; see op.report_output[0] (may want to change SNR threshold)\n",
    "zero_flux_point = op.find_zero_flux_point     # find zero flux points\n",
    "print(op.fr_g[:5], op.fr_e[:5], ok)\n",
    "print(zero_flux_point[\"status\"])\n",
    "for c in zero_flux_point[\"picked\"]:\n",
    "    print(f\"center ≈ {c['center']:.6g}, score={c['score']:.3e}, slope={c['slope']:.3e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb282fc6-2cb0-4eda-980f-ffe566886bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b396fb6e-fb90-4b78-9f2e-b8de62e0e9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0315bdc6-332e-4fb9-b6e4-440d1cb1ab3b",
   "metadata": {},
   "source": [
    "# Test only fits function for double hanger model\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Optional, Callable, Sequence, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "@dataclass\n",
    "class FluxList:\n",
    "    name: str\n",
    "    value: Iterable[float]\n",
    "\n",
    "def _unwrap_and_remove_linear_phase(freq: np.ndarray, sig: np.ndarray) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"Unwrap phase and remove best-fit linear slope (cable delay).\"\"\"\n",
    "    # unwrap and linear fit: angle ≈ φ0 + 2π τ f, so it becomes continuous\n",
    "    ph = np.unwrap(np.angle(sig))\n",
    "    slope = np.polyfit(freq, ph, 1)[0]\n",
    "    sig_unw = sig * np.exp(-1j * slope * freq)\n",
    "    return sig_unw, slope/(2*np.pi)  # return τ estimate in seconds if freq in Hz\n",
    "\n",
    "def _hanger_single(f: np.ndarray, f0, Ql, Qc, theta, a, phi0, tau) -> np.ndarray:\n",
    "    x = (f - f0) / f0\n",
    "    notch = 1.0 - (Ql/Qc) * np.exp(1j*theta) / (1.0 + 2j*Ql*x)\n",
    "    return a * np.exp(1j*(phi0 + 2*np.pi*f*tau)) * notch\n",
    "\n",
    "def _hanger_double_mix(f: np.ndarray, params: Dict[str, float]) -> np.ndarray:\n",
    "    \"\"\"Mixture of two nearby resonances with shared line params, weighted by p_g.\"\"\"\n",
    "    f0g, f0e = params[\"f0g\"], params[\"f0e\"]\n",
    "    Ql, Qc   = params[\"Ql\"],  params[\"Qc\"]\n",
    "    theta    = params[\"theta\"]\n",
    "    a        = params[\"a\"]\n",
    "    phi0     = params[\"phi0\"]\n",
    "    tau      = params[\"tau\"]\n",
    "    pg       = params[\"pg\"]  # in [0,1]\n",
    "    s_g = _hanger_single(f, f0g, Ql, Qc, theta, a, phi0, tau)\n",
    "    s_e = _hanger_single(f, f0e, Ql, Qc, theta, a, phi0, tau)\n",
    "    return pg*s_g + (1.0 - pg)*s_e\n",
    "\n",
    "def _fit_double_hanger(freq: np.ndarray, sig_cplx: np.ndarray):\n",
    "    f = np.asarray(freq, float)\n",
    "    yC = np.asarray(sig_cplx, complex)\n",
    "\n",
    "    # -------- de-embed linear phase (done in your pipeline, but safe here) --------\n",
    "    ph = np.unwrap(np.angle(yC))\n",
    "    b1, b0 = np.polyfit(f, ph, 1)         # ph ≈ b0 + b1 f\n",
    "    y = yC * np.exp(-1j * (b0 + b1*f))    # unwrapped/de-sloped\n",
    "    # NOTE: we fit in this frame; we won't refit tau here.\n",
    "\n",
    "    # -------- initial guesses via local minima on smoothed |S| --------\n",
    "    mag = np.abs(y)\n",
    "    win = max(5, len(f)//80)\n",
    "    mag_s = np.convolve(mag, np.ones(win)/win, mode=\"same\")\n",
    "\n",
    "    # local minima: indices i with mag_s[i] < neighbors\n",
    "    locmins = np.where((mag_s[1:-1] < mag_s[:-2]) & (mag_s[1:-1] < mag_s[2:]))[0] + 1\n",
    "    if len(locmins) == 0:\n",
    "        locmins = np.array([int(np.argmin(mag_s))])\n",
    "    # sort by depth\n",
    "    locmins = locmins[np.argsort(mag_s[locmins])]\n",
    "\n",
    "    # pick the deepest as ground; the closest *distinct* other min as excited\n",
    "    i0 = locmins[0]\n",
    "    # distinct = at least a few bins away\n",
    "    min_sep_bins = max(5, len(f)//200)\n",
    "    candidates = [j for j in locmins[1:] if abs(j - i0) >= min_sep_bins]\n",
    "    j0 = candidates[0] if candidates else (i0 + min_sep_bins if i0 + min_sep_bins < len(f) else i0 - min_sep_bins)\n",
    "\n",
    "    f0g0, f0e0 = np.sort([f[i0], f[j0]])\n",
    "\n",
    "    # -------- line-term seeds (gentle) --------\n",
    "    a0 = float(np.median(mag))\n",
    "    theta0 = 0.0\n",
    "    phi00 = 0.0\n",
    "    tau0 = 0.0\n",
    "    Ql0, Qc0 = 1.5e4, 3.0e4\n",
    "    pg0 = 0.7\n",
    "\n",
    "    # -------- bounds with a narrow f0e window around its seed --------\n",
    "    # estimate natural linewidth ~ f0 / Ql0; allow a wide multiple\n",
    "    linewidth = f0g0 / Ql0\n",
    "    df_win = max(10.0*linewidth, 1.5e6)   # e.g. +/- 1.5 MHz minimum window\n",
    "    lb = dict(f0g=f.min(),  f0e=f0e0 - 4*df_win, Ql=500,  Qc=500,\n",
    "              theta=-np.pi, a=0.0, phi0=-np.pi, tau=-1e-6, pg=0.0)\n",
    "    ub = dict(f0g=f.max(),  f0e=f0e0 + 4*df_win, Ql=5e5, Qc=5e6,\n",
    "              theta= np.pi, a=10*np.max(mag), phi0= np.pi, tau= 1e-6, pg=1.0)\n",
    "\n",
    "    params0 = dict(f0g=f0g0, f0e=f0e0, Ql=Ql0, Qc=Qc0, theta=theta0, a=a0, phi0=phi00, tau=tau0, pg=pg0)\n",
    "\n",
    "    # -------- model & packing --------\n",
    "    def _hanger_single(ff, f0, Ql, Qc, theta, a, phi0, tau):\n",
    "        x = (ff - f0)/f0\n",
    "        notch = 1.0 - (Ql/Qc)*np.exp(1j*theta)/(1.0 + 2j*Ql*x)\n",
    "        return a*np.exp(1j*(phi0 + 2*np.pi*ff*tau))*notch\n",
    "\n",
    "    def _hanger_double_mix(ff, p):\n",
    "        sg = _hanger_single(ff, p[\"f0g\"], p[\"Ql\"], p[\"Qc\"], p[\"theta\"], p[\"a\"], p[\"phi0\"], p[\"tau\"])\n",
    "        se = _hanger_single(ff, p[\"f0e\"], p[\"Ql\"], p[\"Qc\"], p[\"theta\"], p[\"a\"], p[\"phi0\"], p[\"tau\"])\n",
    "        return p[\"pg\"]*sg + (1.0 - p[\"pg\"])*se\n",
    "\n",
    "    keys = [\"f0g\",\"f0e\",\"Ql\",\"Qc\",\"theta\",\"a\",\"phi0\",\"tau\",\"pg\"]\n",
    "    def pack(p):   return np.array([p[k] for k in keys], float)\n",
    "    def unpack(v): return {k: float(x) for k,x in zip(keys, v)}\n",
    "\n",
    "    v0  = pack(params0)\n",
    "    vlb = pack(lb)\n",
    "    vub = pack(ub)\n",
    "\n",
    "    # -------- residual with weights (emphasize dips) --------\n",
    "    # weight ~ 1/(mag_s^2) but bounded to avoid extremes\n",
    "    w = 1.0/np.maximum(mag_s**2, 1e-4)\n",
    "    w = w/np.max(w)\n",
    "    def resid(v):\n",
    "        p = unpack(v)\n",
    "        s = _hanger_double_mix(f, p)\n",
    "        r = np.stack([np.real(s) - np.real(y), np.imag(s) - np.imag(y)], axis=1)\n",
    "        r = (r.T * w).T     # apply weights pointwise to both Re/Im\n",
    "        return r.ravel()\n",
    "\n",
    "    # -------- optimize (SciPy if present, else projected gradient) --------\n",
    "    try:\n",
    "        from scipy.optimize import least_squares\n",
    "        res = least_squares(resid, v0, bounds=(vlb, vub), xtol=1e-12, ftol=1e-12, gtol=1e-12, max_nfev=4000)\n",
    "        vf = res.x\n",
    "    except Exception:\n",
    "        vf = v0.copy()\n",
    "        lr = 2e-6\n",
    "        eps = np.array([5e3, 5e3, 50.0, 50.0, 1e-3, 1e-3, 1e-3, 1e-9, 1e-2])\n",
    "        for _ in range(800):\n",
    "            r0 = resid(vf); base = np.dot(r0, r0)\n",
    "            g = np.zeros_like(vf)\n",
    "            for k in range(len(vf)):\n",
    "                vtmp = vf.copy(); vtmp[k] = np.clip(vtmp[k] + eps[k], vlb[k], vub[k])\n",
    "                r2 = resid(vtmp); g[k] = (np.dot(r2,r2) - base)/eps[k]\n",
    "            vf -= lr*g\n",
    "            vf = np.minimum(np.maximum(vf, vlb), vub)\n",
    "\n",
    "    p_fit = unpack(vf)\n",
    "    # enforce ordering convention\n",
    "    if p_fit[\"f0g\"] > p_fit[\"f0e\"]:\n",
    "        p_fit[\"f0g\"], p_fit[\"f0e\"] = p_fit[\"f0e\"], p_fit[\"f0g\"]\n",
    "        p_fit[\"pg\"] = 1.0 - p_fit[\"pg\"]\n",
    "\n",
    "    # derived Qi and a simple SNR proxy\n",
    "    Qi = (p_fit[\"Ql\"]*p_fit[\"Qc\"])/max(p_fit[\"Qc\"] - p_fit[\"Ql\"], 1e-6)\n",
    "    rr = resid(vf).reshape(-1,2)\n",
    "    noise = np.std(np.hypot(rr[:,0], rr[:,1]))\n",
    "    amp = np.max(mag) - np.min(mag)\n",
    "    snr = float(abs(amp)/(4*max(noise, 1e-12)))\n",
    "    return p_fit, {\"Qi\": Qi}, snr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dda6cc-7ba3-484e-bb4f-8769e6b2f418",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d = np.load(\"s12_fixed_flux_double_circle.npz\")\n",
    "f = d[\"freqs_Hz\"]\n",
    "Sg, Se, Smix = d[\"Sg\"], d[\"Se\"], d[\"Smix\"]\n",
    "\n",
    "# Complex-plane circles\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(Sg.real, Sg.imag, label=\"Sg(f)\")\n",
    "plt.plot(Se.real, Se.imag, label=\"Se(f)\")\n",
    "plt.plot(Smix.real, Smix.imag, label=\"Smix(f)\", linewidth=2)\n",
    "plt.gca().set_aspect(\"equal\", \"box\")\n",
    "plt.xlabel(\"Re{S12}\"); plt.ylabel(\"Im{S12}\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Magnitude/phase vs frequency for the mixture\n",
    "plt.figure(); plt.plot(f/1e9, np.abs(Smix)); plt.xlabel(\"GHz\"); plt.ylabel(\"|S12|\"); plt.show()\n",
    "plt.figure(); plt.plot(f/1e9, np.unwrap(np.angle(Smix))); plt.xlabel(\"GHz\"); plt.ylabel(\"arg(S12)\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e2bd87-6157-48f1-b349-13516833603e",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Load the fixed-flux dataset (Smix is the thing to fit)\n",
    "# ------------------------------------------------------------\n",
    "data = np.load(\"s12_fixed_flux_double_circle.npz\")   # adjust path if needed\n",
    "f_Hz  = data[\"freqs_Hz\"]              # (Nf,)\n",
    "Smix  = data[\"Smix\"]                  # (Nf,), complex\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Same pre-fit helper you used elsewhere\n",
    "# ------------------------------------------------------------\n",
    "def _unwrap_and_remove_linear_phase(freq, sig):\n",
    "    ph = np.unwrap(np.angle(sig))\n",
    "    b1, b0 = np.polyfit(freq, ph, 1)          # ph ~ b0 + b1*f\n",
    "    sig_unw = sig * np.exp(-1j * (b0 + b1*freq))\n",
    "    tau_est = b1 / (2*np.pi)                  # seconds\n",
    "    return sig_unw, tau_est\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Import your fitter (make sure it's on PYTHONPATH)\n",
    "#    from your_module import _fit_double_hanger\n",
    "#    (If it's already defined in your notebook, skip this import.)\n",
    "# ------------------------------------------------------------\n",
    "# from resonator_fit.double_hanger import _fit_double_hanger\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Fit\n",
    "# ------------------------------------------------------------\n",
    "sig_unw, tau_est = _unwrap_and_remove_linear_phase(f_Hz, Smix)\n",
    "p_fit, derived, snr = _fit_double_hanger(f_Hz, sig_unw)\n",
    "\n",
    "fr_g = p_fit[\"f0g\"]     # Hz\n",
    "fr_e = p_fit[\"f0e\"]     # Hz\n",
    "\n",
    "print(f\"fr_g  = {fr_g:.3f} Hz  ({fr_g/1e9:.6f} GHz)\")\n",
    "print(f\"fr_e  = {fr_e:.3f} Hz  ({fr_e/1e9:.6f} GHz)\")\n",
    "print(f\"Ql    = {p_fit['Ql']:.3f},  Qc = {p_fit['Qc']:.3f},  Qi (derived) = {derived['Qi']:.3f}\")\n",
    "print(f\"pg    = {p_fit['pg']:.3f},  theta = {p_fit['theta']:.3f}, a = {p_fit['a']:.6f}\")\n",
    "print(f\"tau (unwrap est) ≈ {tau_est*1e9:.3f} ns,  SNR proxy = {snr:.3f}\")\n",
    "\n",
    "\n",
    "# model generated from fitted params in the *unwrapped* frame\n",
    "S_model_unw = _hanger_double_mix(f_Hz, p_fit)\n",
    "\n",
    "# align global complex gain/phase to the original data for a fair overlay:\n",
    "scale = np.mean(Smix) / np.mean(S_model_unw)\n",
    "S_model = S_model_unw * scale\n",
    "\n",
    "plt.figure(figsize=(7.5,4.5))\n",
    "plt.plot(f_Hz/1e9, np.abs(Smix),  label=\"data |S12|\", alpha=0.7)\n",
    "plt.plot(f_Hz/1e9, np.abs(S_model), label=\"fit  |S12|\", lw=2)\n",
    "plt.xlabel(\"Frequency (GHz)\"); plt.ylabel(\"|S12|\"); plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3393b981-ec4c-41b1-80a6-5c62dc2b3bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
